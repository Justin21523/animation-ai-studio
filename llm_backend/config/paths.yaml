# Unified Path Configuration for Animation AI Studio
# All projects share these paths to avoid duplication

# =============================================================================
# Hardware Configuration
# =============================================================================
hardware:
  # CPU
  cpu:
    model: "AMD Ryzen 9 9950X"
    cores: 16
    threads: 32

  # RAM
  ram:
    total_gb: 64

  # GPU
  gpu:
    model: "NVIDIA RTX 5080"
    vram_gb: 16
    count: 1

  # PyTorch
  pytorch:
    version: "2.7.0"
    cuda_version: "12.8"
    conda_env: "ai_env"

# =============================================================================
# Shared Storage Paths
# =============================================================================
storage:
  # AI Warehouse - Shared model storage
  ai_warehouse: "/mnt/c/AI_LLM_projects/ai_warehouse"

  # Data storage - Shared datasets
  data_root: "/mnt/data/ai_data"

  # Project root
  project_root: "/mnt/c/AI_LLM_projects/animation-ai-studio"

# =============================================================================
# Model Paths (AI Warehouse)
# =============================================================================
models:
  # LLM models
  llm:
    base_path: "/mnt/c/AI_LLM_projects/ai_warehouse/models/llm"

    # Qwen models
    qwen:
      # 7B models (fit in 16GB VRAM)
      qwen2_5_vl_7b: "qwen/Qwen2.5-VL-7B-Instruct"
      qwen2_5_14b: "qwen/Qwen2.5-14B-Instruct"
      qwen2_5_coder_7b: "qwen/Qwen2.5-Coder-7B-Instruct"

      # 72B quantized (INT4, fits in 16GB but slower)
      qwen2_5_vl_72b_gptq: "qwen/Qwen2.5-VL-72B-Instruct-GPTQ-Int4"
      qwen2_5_72b_awq: "qwen/Qwen2.5-72B-Instruct-AWQ"

    # DeepSeek models
    deepseek:
      # R1 distilled to 7B/14B
      r1_distill_qwen_7b: "deepseek/DeepSeek-R1-Distill-Qwen-7B"
      r1_distill_qwen_14b: "deepseek/DeepSeek-R1-Distill-Qwen-14B"

    # Llama models
    llama:
      llama_3_2_11b_vision: "meta-llama/Llama-3.2-11B-Vision-Instruct"
      llama_3_3_70b_awq: "meta-llama/Llama-3.3-70B-Instruct-AWQ"

  # Computer Vision models
  cv:
    base_path: "/mnt/c/AI_LLM_projects/ai_warehouse/models/cv"
    sam2: "sam2/sam2_hiera_large"
    depth_anything: "depth-anything/Depth-Anything-V2-Large"

  # Image Generation models
  image_gen:
    base_path: "/mnt/c/AI_LLM_projects/ai_warehouse/models/image_gen"
    sdxl_base: "stabilityai/stable-diffusion-xl-base-1.0"
    controlnet:
      openpose: "lllyasviel/control_v11p_sd15_openpose"
      depth: "lllyasviel/control_v11f1p_sd15_depth"
      canny: "lllyasviel/control_v11p_sd15_canny"
    lora:
      base_path: "/mnt/c/AI_LLM_projects/ai_warehouse/models/lora"
      # LoRAs from 3d-animation-lora-pipeline
      characters: "characters"
      backgrounds: "backgrounds"
      styles: "styles"

  # Audio models
  audio:
    base_path: "/mnt/c/AI_LLM_projects/ai_warehouse/models/audio"
    gpt_sovits: "gpt-sovits/pretrained"
    whisper_large_v3: "openai/whisper-large-v3"

  # Enhancement models
  enhancement:
    base_path: "/mnt/c/AI_LLM_projects/ai_warehouse/models/enhancement"
    realesrgan: "realesrgan/RealESRGAN_x4plus_anime_6B"
    gfpgan: "gfpgan/GFPGANv1.4"

# =============================================================================
# Dataset Paths (Shared with LoRA Pipeline)
# =============================================================================
datasets:
  # 3D Animation datasets
  anime_3d:
    base_path: "/mnt/data/ai_data/datasets/3d-anime"

    films:
      luca:
        frames: "luca/frames"
        audio: "luca/audio"
        metadata: "luca/metadata"
        segmented: "luca/segmented"

      coco:
        frames: "coco/frames"
        audio: "coco/audio"
        metadata: "coco/metadata"

      # Add other films as needed

# =============================================================================
# Cache Configuration
# =============================================================================
cache:
  # HuggingFace cache (unified)
  huggingface: "/mnt/c/AI_LLM_projects/ai_warehouse/cache/huggingface"

  # PyTorch cache
  torch: "/mnt/c/AI_LLM_projects/ai_warehouse/cache/torch"

  # vLLM cache
  vllm: "/mnt/c/AI_LLM_projects/ai_warehouse/cache/vllm"

  # Redis cache
  redis:
    host: "localhost"
    port: 6379
    db: 0

# =============================================================================
# Output Paths
# =============================================================================
outputs:
  base_path: "/mnt/c/AI_LLM_projects/animation-ai-studio/outputs"

  # Organized by type
  analysis: "analysis"
  generation: "generation"
  processing: "processing"
  final: "final"

# =============================================================================
# Logs
# =============================================================================
logs:
  base_path: "/mnt/c/AI_LLM_projects/animation-ai-studio/logs"
  retention_days: 7

# =============================================================================
# Temporary Files
# =============================================================================
temp:
  base_path: "/tmp/animation-ai-studio"
  cleanup_on_exit: true
