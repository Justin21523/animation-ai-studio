# File Organizer é…ç½®ç¯„ä¾‹
# =========================
#
# æ­¤æª”æ¡ˆæä¾› File Organizer çš„å®Œæ•´é…ç½®ç¯„ä¾‹
# File Organizer ä¸»è¦é€é CLI ä½¿ç”¨ï¼Œä½†å¯ä»¥ä½¿ç”¨ shell script çµ„åˆè¤‡é›œå·¥ä½œæµç¨‹

# ============================================================================
# åŸºæœ¬ä½¿ç”¨ç¯„ä¾‹ï¼ˆé€é CLIï¼‰
# ============================================================================

# ç¯„ä¾‹ 1ï¼šæŒ‰é¡å‹çµ„ç¹”
# python scripts/automation/scenarios/file_organizer.py \
#   --skip-preflight \
#   organize-by-type \
#   --input /path/to/input \
#   --output /path/to/output

# ç¯„ä¾‹ 2ï¼šå°‹æ‰¾é‡è¤‡æª”æ¡ˆ
# python scripts/automation/scenarios/file_organizer.py \
#   --skip-preflight \
#   find-duplicates \
#   --input /path/to/check \
#   --method hash

# ============================================================================
# å·¥ä½œæµç¨‹ç¯„ä¾‹ 1ï¼šå®Œæ•´ä¸‹è¼‰è³‡æ–™å¤¾æ¸…ç†
# ============================================================================

workflow_download_cleanup:
  description: "æ¸…ç†é›œäº‚çš„ä¸‹è¼‰è³‡æ–™å¤¾"

  steps:
    - name: "å°‹æ‰¾é‡è¤‡æª”æ¡ˆ"
      command: |
        python scripts/automation/scenarios/file_organizer.py \
          --skip-preflight \
          find-duplicates \
          --input ~/Downloads \
          --method hash \
          --min-size 1048576 \
          --output-json /tmp/duplicates_$(date +%Y%m%d).json

    - name: "æŒ‰é¡å‹çµ„ç¹”"
      command: |
        python scripts/automation/scenarios/file_organizer.py \
          --skip-preflight \
          organize-by-type \
          --input ~/Downloads \
          --output ~/Organized \
          --move

    - name: "åˆ†æçµæœ"
      command: |
        python scripts/automation/scenarios/file_organizer.py \
          --skip-preflight \
          analyze-disk-space \
          --input ~/Organized \
          --depth 2

# ============================================================================
# å·¥ä½œæµç¨‹ç¯„ä¾‹ 2ï¼šç…§ç‰‡æ•´ç†
# ============================================================================

workflow_photo_organization:
  description: "æŒ‰æ—¥æœŸçµ„ç¹”ç…§ç‰‡ä¸¦å°‹æ‰¾é‡è¤‡"

  input_dir: "/path/to/Photos"
  output_dir: "/path/to/Photos_by_Date"

  steps:
    - name: "æŒ‰æ—¥æœŸçµ„ç¹”"
      command: |
        python scripts/automation/scenarios/file_organizer.py \
          --skip-preflight \
          organize-by-date \
          --input ${input_dir} \
          --output ${output_dir} \
          --date-format "%Y/%m"

    - name: "å°‹æ‰¾é‡è¤‡ç…§ç‰‡"
      command: |
        python scripts/automation/scenarios/file_organizer.py \
          --skip-preflight \
          find-duplicates \
          --input ${output_dir} \
          --method hash \
          --output-json /tmp/photo_duplicates.json

# ============================================================================
# å·¥ä½œæµç¨‹ç¯„ä¾‹ 3ï¼šå°ˆæ¡ˆæ­¸æª”
# ============================================================================

workflow_project_archiving:
  description: "æ•´ç†èˆŠå°ˆæ¡ˆæª”æ¡ˆ"

  projects_dir: "/path/to/Projects"
  archive_dir: "/path/to/Archive"
  cutoff_date: "2024-06-01"

  steps:
    - name: "æœå°‹èˆŠæª”æ¡ˆ"
      command: |
        python scripts/automation/scenarios/file_organizer.py \
          --skip-preflight \
          search \
          --input ${projects_dir} \
          --modified-before ${cutoff_date} \
          --output-list /tmp/old_files.txt

    - name: "åˆ†æç©ºé–“"
      command: |
        python scripts/automation/scenarios/file_organizer.py \
          --skip-preflight \
          analyze-disk-space \
          --input ${projects_dir} \
          --depth 3 \
          --output-json /tmp/space_analysis.json

    - name: "æ­¸æª”"
      command: |
        python scripts/automation/scenarios/file_organizer.py \
          --skip-preflight \
          organize-by-date \
          --input ${projects_dir} \
          --output ${archive_dir} \
          --date-format "%Y-Q%m" \
          --move

# ============================================================================
# å·¥ä½œæµç¨‹ç¯„ä¾‹ 4ï¼šé‡è¤‡æª”æ¡ˆæ¸…ç†
# ============================================================================

workflow_duplicate_cleanup:
  description: "å°‹æ‰¾ä¸¦å ±å‘Šé‡è¤‡æª”æ¡ˆ"

  steps:
    - name: "å¿«é€Ÿç¯©é¸ï¼ˆæŒ‰å¤§å°ï¼‰"
      command: |
        python scripts/automation/scenarios/file_organizer.py \
          --skip-preflight \
          find-duplicates \
          --input /path/to/data \
          --method size \
          --min-size 10485760 \
          --output-json /tmp/duplicates_size.json

    - name: "ç²¾ç¢ºç¢ºèªï¼ˆæŒ‰ hashï¼‰"
      command: |
        python scripts/automation/scenarios/file_organizer.py \
          --skip-preflight \
          find-duplicates \
          --input /path/to/data \
          --method hash \
          --min-size 10485760 \
          --output-json /tmp/duplicates_hash.json

# ============================================================================
# å·¥ä½œæµç¨‹ç¯„ä¾‹ 5ï¼šæ‰¹æ¬¡é‡å‘½å
# ============================================================================

workflow_batch_rename:
  description: "æ‰¹æ¬¡é‡å‘½åæª”æ¡ˆ"

  steps:
    - name: "é‡å‘½åç…§ç‰‡ï¼ˆregexï¼‰"
      command: |
        python scripts/automation/scenarios/file_organizer.py \
          --skip-preflight \
          batch-rename \
          --input /path/to/photos \
          --pattern "IMG_(\d{4}).jpg" \
          --replacement "photo_\1.jpg" \
          --use-regex

    - name: "é‡å‘½åå‚™ä»½ï¼ˆglobï¼‰"
      command: |
        python scripts/automation/scenarios/file_organizer.py \
          --skip-preflight \
          batch-rename \
          --input /path/to/backups \
          --pattern "*.bak" \
          --replacement "backup_*.txt"

# ============================================================================
# å·¥ä½œæµç¨‹ç¯„ä¾‹ 6ï¼šå®šæœŸç¶­è­·è…³æœ¬
# ============================================================================

workflow_weekly_maintenance:
  description: "æ¯é€±åŸ·è¡Œçš„ç¶­è­·ä»»å‹™"
  schedule: "weekly"

  steps:
    - name: "å°‹æ‰¾é‡è¤‡æª”æ¡ˆ"
      command: |
        python scripts/automation/scenarios/file_organizer.py \
          --skip-preflight \
          find-duplicates \
          --input /data \
          --method hash \
          --output-json /var/log/duplicates_$(date +%Y%m%d).json

    - name: "ç©ºé–“åˆ†æ"
      command: |
        python scripts/automation/scenarios/file_organizer.py \
          --skip-preflight \
          analyze-disk-space \
          --input /data \
          --depth 3 \
          --output-json /var/log/space_$(date +%Y%m%d).json

    - name: "æœå°‹èˆŠæª”æ¡ˆ"
      command: |
        python scripts/automation/scenarios/file_organizer.py \
          --skip-preflight \
          search \
          --input /data \
          --modified-before $(date -d '1 year ago' +%Y-%m-%d) \
          --output-list /var/log/old_files.txt

# ============================================================================
# Shell Script ç¯„ä¾‹
# ============================================================================

# cleanup_downloads.sh
# #!/bin/bash
# set -e
#
# DOWNLOADS="$HOME/Downloads"
# ORGANIZED="$HOME/Organized"
# DATE=$(date +%Y%m%d)
#
# echo "ğŸš€ Starting download cleanup..."
#
# # Step 1: Find duplicates
# echo "ğŸ” Finding duplicates..."
# python scripts/automation/scenarios/file_organizer.py \
#   --skip-preflight \
#   find-duplicates \
#   --input "$DOWNLOADS" \
#   --method hash \
#   --min-size 1048576 \
#   --output-json "/tmp/duplicates_$DATE.json"
#
# # Step 2: Organize by type
# echo "ğŸ“‚ Organizing by type..."
# python scripts/automation/scenarios/file_organizer.py \
#   --skip-preflight \
#   organize-by-type \
#   --input "$DOWNLOADS" \
#   --output "$ORGANIZED" \
#   --move
#
# # Step 3: Analyze
# echo "ğŸ“Š Analyzing..."
# python scripts/automation/scenarios/file_organizer.py \
#   --skip-preflight \
#   analyze-disk-space \
#   --input "$ORGANIZED" \
#   --depth 2
#
# echo "âœ… Cleanup complete!"

# ============================================================================
# é€²éšç¯„ä¾‹ï¼šèˆ‡å…¶ä»–å·¥å…·æ•´åˆ
# ============================================================================

integration_with_image_processor:
  description: "æ•´åˆ File Organizer å’Œ Image Processor"

  steps:
    - name: "æœå°‹å¤§å‹åœ–åƒ"
      command: |
        python scripts/automation/scenarios/file_organizer.py \
          --skip-preflight \
          search \
          --input /path/to/photos \
          --extension .jpg \
          --min-size 5242880 \
          --output-list /tmp/large_images.txt

    - name: "æ‰¹æ¬¡æœ€ä½³åŒ–"
      command: |
        while read img; do
          python scripts/automation/scenarios/image_processor.py \
            --operation optimize \
            --input "$img" \
            --output "${img%.jpg}_optimized.jpg" \
            --quality 85
        done < /tmp/large_images.txt

integration_with_video_processor:
  description: "æ•´åˆ File Organizer å’Œ Video Processor"

  steps:
    - name: "æå– frames"
      command: |
        python scripts/automation/scenarios/video_processor.py \
          extract \
          --input /path/to/video.mp4 \
          --output /tmp/frames

    - name: "æŒ‰æ—¥æœŸçµ„ç¹” frames"
      command: |
        python scripts/automation/scenarios/file_organizer.py \
          --skip-preflight \
          organize-by-date \
          --input /tmp/frames \
          --output /path/to/organized_frames \
          --date-format "%Y/%m/%d"

# ============================================================================
# åƒæ•¸å®Œæ•´ç¯„ä¾‹
# ============================================================================

complete_parameter_examples:

  organize_by_type:
    command: |
      python scripts/automation/scenarios/file_organizer.py \
        --dry-run \
        --skip-preflight \
        organize-by-type \
        --input /path/to/input \
        --output /path/to/output \
        --no-subdirs \
        --move

  organize_by_date:
    command: |
      python scripts/automation/scenarios/file_organizer.py \
        --dry-run \
        --skip-preflight \
        organize-by-date \
        --input /path/to/input \
        --output /path/to/output \
        --date-format "%Y/%m/%d" \
        --use-created-date \
        --move

  batch_rename:
    command: |
      python scripts/automation/scenarios/file_organizer.py \
        --dry-run \
        --skip-preflight \
        batch-rename \
        --input /path/to/files \
        --pattern "IMG_(\d+).jpg" \
        --replacement "photo_\1.jpg" \
        --use-regex \
        --recursive

  find_duplicates:
    command: |
      python scripts/automation/scenarios/file_organizer.py \
        --skip-preflight \
        find-duplicates \
        --input /path/to/check \
        --method hash \
        --no-recursive \
        --min-size 1048576 \
        --output-json /path/to/report.json

  analyze_disk_space:
    command: |
      python scripts/automation/scenarios/file_organizer.py \
        --skip-preflight \
        analyze-disk-space \
        --input /path/to/analyze \
        --depth 3 \
        --top-n 50 \
        --output-json /path/to/analysis.json

  search:
    command: |
      python scripts/automation/scenarios/file_organizer.py \
        --skip-preflight \
        search \
        --input /path/to/search \
        --name-pattern "*.jpg" \
        --extension .jpg \
        --min-size 1048576 \
        --max-size 10485760 \
        --modified-after 2024-01-01 \
        --modified-before 2024-12-31 \
        --no-recursive \
        --output-list /path/to/results.txt

# ============================================================================
# Dry-run æ¸¬è©¦ç¯„ä¾‹
# ============================================================================

dry_run_testing:
  description: "ä½¿ç”¨ dry-run é è¦½æ“ä½œ"

  steps:
    - name: "é è¦½çµ„ç¹”"
      command: |
        python scripts/automation/scenarios/file_organizer.py \
          --dry-run \
          --skip-preflight \
          organize-by-type \
          --input /path/to/test \
          --output /path/to/output
      note: "æª¢æŸ¥è¼¸å‡ºï¼Œç¢ºèªç„¡èª¤å¾Œç§»é™¤ --dry-run"

    - name: "å¯¦éš›åŸ·è¡Œ"
      command: |
        python scripts/automation/scenarios/file_organizer.py \
          --skip-preflight \
          organize-by-type \
          --input /path/to/test \
          --output /path/to/output

# ============================================================================
# æœ€ä½³å¯¦è¸
# ============================================================================

best_practices:

  backup_first:
    description: "æ°¸é å…ˆå‚™ä»½"
    command: |
      cp -r /path/to/important /path/to/backup
      # æˆ–ä½¿ç”¨ rsync
      rsync -av /path/to/important/ /path/to/backup/

  test_small_batch:
    description: "å…ˆæ¸¬è©¦å°æ‰¹æ¬¡"
    command: |
      python scripts/automation/scenarios/file_organizer.py \
        --dry-run \
        --skip-preflight \
        organize-by-type \
        --input /path/to/test_folder \
        --output /path/to/test_output

  log_operations:
    description: "è¨˜éŒ„æ‰€æœ‰æ“ä½œ"
    command: |
      python scripts/automation/scenarios/file_organizer.py \
        ... \
        2>&1 | tee -a /var/log/file_organizer_$(date +%Y%m%d).log

  incremental_processing:
    description: "åˆ†æ‰¹è™•ç†å¤§é‡æª”æ¡ˆ"
    command: |
      find /huge/directory -maxdepth 1 -type d | while read subdir; do
        python scripts/automation/scenarios/file_organizer.py \
          --skip-preflight \
          organize-by-type \
          --input "$subdir" \
          --output /organized
      done

# ============================================================================
# è‡ªå‹•åŒ–æ’ç¨‹ç¯„ä¾‹
# ============================================================================

# Cron ç¯„ä¾‹ï¼ˆLinux/Macï¼‰
#
# # æ¯å¤©å‡Œæ™¨ 2 é»åŸ·è¡Œæ¸…ç†
# 0 2 * * * /path/to/cleanup_script.sh
#
# # æ¯é€±æ—¥å‡Œæ™¨ 3 é»åŸ·è¡Œç¶­è­·
# 0 3 * * 0 /path/to/weekly_maintenance.sh
#
# # æ¯æœˆ 1 è™ŸåŸ·è¡Œæ­¸æª”
# 0 4 1 * * /path/to/monthly_archive.sh

# Windows Task Scheduler ç¯„ä¾‹
#
# schtasks /create /sc daily /tn "Daily Cleanup" /tr "C:\path\to\cleanup_script.bat" /st 02:00

# ============================================================================
# é€²éšæ‡‰ç”¨ç¯„ä¾‹
# ============================================================================

advanced_use_cases:

  media_library_organization:
    description: "å®Œæ•´åª’é«”åº«çµ„ç¹”"
    steps:
      - "æŒ‰é¡å‹åˆ†é¡ï¼ˆå½±ç‰‡/éŸ³è¨Š/åœ–åƒï¼‰"
      - "æŒ‰æ—¥æœŸçµ„ç¹”æ¯å€‹é¡åˆ¥"
      - "å°‹æ‰¾ä¸¦ç§»é™¤é‡è¤‡"
      - "ç”Ÿæˆç´¢å¼•å ±å‘Š"

  project_workspace_cleanup:
    description: "å°ˆæ¡ˆå·¥ä½œå€æ¸…ç†"
    steps:
      - "æœå°‹è‡¨æ™‚æª”æ¡ˆ"
      - "ç§»é™¤ç·¨è­¯ç”¢ç‰©"
      - "çµ„ç¹”åŸå§‹æª”æ¡ˆ"
      - "æ­¸æª”èˆŠç‰ˆæœ¬"

  backup_verification:
    description: "å‚™ä»½é©—è­‰"
    steps:
      - "æ¯”è¼ƒåŸå§‹å’Œå‚™ä»½ç›®éŒ„"
      - "å°‹æ‰¾éºæ¼æª”æ¡ˆ"
      - "é©—è­‰æª”æ¡ˆå®Œæ•´æ€§ï¼ˆhashï¼‰"
      - "ç”Ÿæˆå·®ç•°å ±å‘Š"

# ============================================================================
# æ•ˆèƒ½èª¿æ ¡
# ============================================================================

performance_tuning:

  large_file_processing:
    description: "è™•ç†å¤§é‡æª”æ¡ˆ"
    recommendations:
      - "ä½¿ç”¨ --no-recursive åˆ†å±¤è™•ç†"
      - "é™åˆ¶ --depth æ¸›å°‘æƒææ·±åº¦"
      - "å…ˆç”¨ --method size å¿«é€Ÿç¯©é¸"
      - "åˆ†æ‰¹è™•ç†è€Œéä¸€æ¬¡å…¨éƒ¨"

  memory_optimization:
    description: "è¨˜æ†¶é«”æœ€ä½³åŒ–"
    recommendations:
      - "è™•ç†å¤§æª”æ¡ˆæ™‚é™ä½ä¸¦è¡Œåº¦"
      - "é¿å…åŒæ™‚é‹è¡Œå¤šå€‹å¯¦ä¾‹"
      - "å®šæœŸæ¸…ç†è‡¨æ™‚æª”æ¡ˆ"

  network_drives:
    description: "ç¶²è·¯ç£ç¢Ÿè™•ç†"
    recommendations:
      - "é¿å…è·¨ç¶²è·¯è¤‡è£½/ç§»å‹•"
      - "å…ˆåŒæ­¥åˆ°æœ¬æ©Ÿå†è™•ç†"
      - "ä½¿ç”¨ rsync æ›¿ä»£ç›´æ¥æ“ä½œ"

# ============================================================================
# éŒ¯èª¤è™•ç†
# ============================================================================

error_handling:

  permission_errors:
    solution: |
      # æª¢æŸ¥æ¬Šé™
      ls -la /path/to/file
      # ä¿®å¾©æ¬Šé™
      chmod +r /path/to/file

  file_locks:
    solution: |
      # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦è¢«é–å®š
      lsof /path/to/file
      # ç­‰å¾…é‡‹æ”¾æˆ–å¼·åˆ¶é—œé–‰ç¨‹åº

  disk_full:
    solution: |
      # æª¢æŸ¥ç£ç¢Ÿç©ºé–“
      df -h
      # æ¸…ç†ç©ºé–“
      python scripts/automation/scenarios/file_organizer.py \
        analyze-disk-space \
        --input /path \
        --output-json /tmp/analysis.json

# ============================================================================
# çµå°¾èªªæ˜
# ============================================================================

notes:
  - "File Organizer ä¸»è¦é€é CLI ä½¿ç”¨"
  - "ä½¿ç”¨ shell script çµ„åˆè¤‡é›œå·¥ä½œæµç¨‹"
  - "æ°¸é å…ˆå‚™ä»½é‡è¦è³‡æ–™"
  - "ä½¿ç”¨ --dry-run é è¦½çµæœ"
  - "è¨˜éŒ„æ‰€æœ‰æ“ä½œä»¥ä¾¿è¿½è¹¤"
  - "å®šæœŸåŸ·è¡Œç¶­è­·ä»»å‹™"
  - "æ•´åˆå…¶ä»– Phase 2 å·¥å…·å¯¦ç¾å®Œæ•´è‡ªå‹•åŒ–"
