# Claude Code Onboarding Guide

**Purpose:** Quick-start guide for new Claude Code sessions
**Last Updated:** 2025-11-17
**Languages:** English (primary), Traditional Chinese (marked sections)

> **Consolidated Documentation**
> This document provides bilingual onboarding instructions for Claude Code, organized by modules rather than time periods.

---

## ğŸ“‹ Quick Start for New Claude Code Session

### Opening Message Template (English)

```
I'm working on Animation AI Studio, an LLM-driven AI platform for
3D animation content creation.

CRITICAL Requirements:
1. âœ… All models OPEN-SOURCE only (Qwen2.5-VL, Qwen2.5-14B, etc.)
2. âœ… Self-hosted vLLM backend (NO Ollama)
3. âœ… LLM as creative decision engine (brain, not just tool)
4. âœ… Optimized for 3D animation (Pixar-style)
5. âœ… LangGraph for agent framework

Hardware: RTX 5080 16GB VRAM (single GPU)
PyTorch: 2.7.0 + CUDA 12.8 (IMMUTABLE)

Please read in order:
1. docs/modules/module-progress.md - Current module status
2. docs/architecture/project-architecture.md - Overall architecture
3. CLAUDE.md - Complete project instructions
4. OPEN_SOURCE_MODELS.md - All models and tools

Current working directory: /mnt/c/AI_LLM_projects/animation-ai-studio

My task: [describe what you want to work on]
```

---

## ğŸ“‹ é–‹å ´è¨Šæ¯ç¯„æœ¬ (ç¹é«”ä¸­æ–‡)

```
æˆ‘æ­£åœ¨é–‹ç™¼ Animation AI Studio å°ˆæ¡ˆï¼Œé€™æ˜¯ä¸€å€‹ä½¿ç”¨é–‹æºLLMé©…å‹•çš„AIå‹•ç•«å‰µä½œå¹³å°ã€‚

æ ¸å¿ƒè¦æ±‚ï¼š
1. âœ… åªèƒ½ä½¿ç”¨é–‹æºæ¨¡å‹ (Qwen2.5-VL, Qwen2.5-14B, GPT-SoVITSç­‰)
2. âœ… è‡ªå»ºLLMæœå‹™å¾Œç«¯ (vLLM) - çµ•å°ä¸ä½¿ç”¨Ollama
3. âœ… LLMä½œç‚ºå‰µæ„æ±ºç­–å¼•æ“ (å¤§è…¦ï¼Œä¸åªæ˜¯å·¥å…·)
4. âœ… é‡å°3Då‹•ç•«è§’è‰²å„ªåŒ– (Pixaré¢¨æ ¼)
5. âœ… LangGraphä½œç‚ºAgentæ¡†æ¶

ç¡¬é«”: RTX 5080 16GB VRAM (å–®ä¸€GPU)
PyTorch: 2.7.0 + CUDA 12.8 (çµ•å°ä¸å¯ä¿®æ”¹)

è«‹å…ˆé–±è®€é€™äº›æ–‡æª” (æŒ‰é †åº):
1. docs/modules/module-progress.md - ç•¶å‰æ¨¡çµ„ç‹€æ…‹
2. docs/architecture/project-architecture.md - å°ˆæ¡ˆæ•´é«”æ¶æ§‹
3. CLAUDE.md - å®Œæ•´å°ˆæ¡ˆæŒ‡å—
4. OPEN_SOURCE_MODELS.md - æ‰€æœ‰å·¥å…·æ¸…å–®

ç•¶å‰å·¥ä½œç›®éŒ„: /mnt/c/AI_LLM_projects/animation-ai-studio

æˆ‘æƒ³è¦åšçš„æ˜¯: [æè¿°æ‚¨çš„å…·é«”ä»»å‹™]
```

---

## ğŸ¯ Core Concepts / æ ¸å¿ƒæ¦‚å¿µ

### Project Purpose

**English:**
- Create, analyze, and transform 3D animated content
- LLM agents make creative decisions autonomously
- Coordinate 50+ specialized AI tools
- Optimize for Pixar-style character consistency

**ç¹é«”ä¸­æ–‡ï¼š**
- å‰µå»ºã€åˆ†æã€è½‰æ› 3D å‹•ç•«å…§å®¹
- LLM Agent è‡ªä¸»åšå‰µæ„æ±ºç­–
- å”èª¿ 50+ å°ˆæ¥­ AI å·¥å…·
- å„ªåŒ– Pixar é¢¨æ ¼è§’è‰²ä¸€è‡´æ€§

### Architecture: LLM + RAG + Agent (ç¼ºä¸€ä¸å¯)

```
Creative Studio (å¤§å£“è»¸)
           â†“ æ•´åˆæ‰€æœ‰æ¨¡çµ„
Agent Framework + RAG (æ ¸å¿ƒæ±ºç­–)
           â†“ èª¿ç”¨å·¥å…·
Generation Tools (å·¥å…·åº«) - Current Focus
           â†“ ä½¿ç”¨æ¨ç†æœå‹™
LLM Backend (åŸºç¤è¨­æ–½) âœ… Complete
```

**English:**
- **LLM**: Understand intent, plan execution, evaluate quality
- **RAG**: Retrieve character info, style guides, past work
- **Agent**: Autonomous tool selection, composition, iteration

**ç¹é«”ä¸­æ–‡ï¼š**
- **LLM**: ç†è§£æ„åœ–ã€è¦åŠƒåŸ·è¡Œã€è©•ä¼°å“è³ª
- **RAG**: æª¢ç´¢è§’è‰²è³‡è¨Šã€é¢¨æ ¼æŒ‡å—ã€éå¾€ä½œå“
- **Agent**: è‡ªä¸»é¸æ“‡å·¥å…·ã€çµ„åˆã€è¿­ä»£å„ªåŒ–

---

## ğŸ“š Documentation Reading Order / æ–‡æª”é–±è®€é †åº

### For Quick Context / å¿«é€Ÿäº†è§£

1. **This File** - Quick onboarding
2. **[docs/modules/module-progress.md](../modules/module-progress.md)** - Current module status
3. **[docs/architecture/project-architecture.md](../architecture/project-architecture.md)** - Overall architecture
4. **[CLAUDE.md](../../CLAUDE.md)** - Complete project guide

### For Implementation / å¯¦ä½œæ™‚

5. **[docs/modules/llm-backend-completion.md](../modules/llm-backend-completion.md)** - LLM Backend completion
6. **[docs/modules/image-generation.md](../modules/image-generation.md)** - Image generation module
7. **[docs/modules/voice-synthesis.md](../modules/voice-synthesis.md)** - Voice synthesis module
8. **[OPEN_SOURCE_MODELS.md](../../OPEN_SOURCE_MODELS.md)** - Models reference

### For Technical Details / æŠ€è¡“ç´°ç¯€

9. **[docs/architecture/llm-backend.md](../architecture/llm-backend.md)** - LLM backend design
10. **[docs/reference/hardware-optimization.md](../reference/hardware-optimization.md)** - Hardware optimization
11. **[llm_backend/README.md](../../llm_backend/README.md)** - LLM backend usage
12. **[llm_backend/HARDWARE_SPECS.md](../../llm_backend/HARDWARE_SPECS.md)** - Hardware specs

---

## ğŸ–¥ï¸ Hardware Configuration / ç¡¬é«”é…ç½®

### Actual Hardware (CRITICAL) / å¯¦éš›ç¡¬é«” (é—œéµ)

```yaml
CPU: AMD Ryzen 9 9950X (16 cores, 32 threads)
RAM: 64GB DDR5
GPU: NVIDIA RTX 5080 16GB VRAM (single card)
PyTorch: 2.7.0 (CANNOT MODIFY / çµ•å°ä¸å¯ä¿®æ”¹)
CUDA: 12.8 (CANNOT MODIFY / çµ•å°ä¸å¯ä¿®æ”¹)
Environment: conda ai_env
```

### VRAM Constraints / VRAM é™åˆ¶

**English:**
- LLM (7B/14B): 12-14GB
- SDXL + LoRA: 13-15GB
- **Can only run ONE heavy model at a time**
- Dynamic switching takes 20-35 seconds

**ç¹é«”ä¸­æ–‡ï¼š**
- LLM (7B/14B): 12-14GB
- SDXL + LoRA: 13-15GB
- **ä¸€æ¬¡åªèƒ½é‹è¡Œä¸€å€‹é‡å‹æ¨¡å‹**
- å‹•æ…‹åˆ‡æ›éœ€è¦ 20-35 ç§’

**See:** [docs/reference/hardware-optimization.md](../reference/hardware-optimization.md)

---

## âš ï¸ CRITICAL: What NOT to Use / çµ•å°ç¦æ­¢ä½¿ç”¨

### âŒ Forbidden

**English:**
- Ollama (we use self-hosted vLLM)
- GPT-4, Claude 3, Gemini (closed-source)
- Any paid APIs
- xformers (breaks PyTorch 2.7.0 compatibility)
- Modifying PyTorch version
- Modifying CUDA version

**ç¹é«”ä¸­æ–‡ï¼š**
- Ollama (æˆ‘å€‘ä½¿ç”¨è‡ªå»º vLLM)
- GPT-4, Claude 3, Gemini (é–‰æº)
- ä»»ä½•ä»˜è²» API
- xformers (ç ´å£ PyTorch 2.7.0 ç›¸å®¹æ€§)
- ä¿®æ”¹ PyTorch ç‰ˆæœ¬
- ä¿®æ”¹ CUDA ç‰ˆæœ¬

### âœ… Required

**English:**
- vLLM (LLM inference)
- Qwen2.5-VL-7B, Qwen2.5-14B, Qwen2.5-Coder-7B
- LangGraph (agent framework)
- FastAPI (gateway)
- Redis (caching)
- PyTorch SDPA (attention backend)

**ç¹é«”ä¸­æ–‡ï¼š**
- vLLM (LLM æ¨ç†)
- Qwen2.5-VL-7B, Qwen2.5-14B, Qwen2.5-Coder-7B
- LangGraph (Agent æ¡†æ¶)
- FastAPI (é–˜é“)
- Redis (å¿«å–)
- PyTorch SDPA (æ³¨æ„åŠ›å¾Œç«¯)

---

## ğŸ¯ Module-Specific Instructions / æ¨¡çµ„å…·é«”èªªæ˜

### Module 1: LLM Backend âœ… COMPLETE

**English:**
```
Status: Production ready (2025-11-16)

Completed:
- vLLM services deployed (Qwen2.5-VL-7B, Qwen2.5-14B, Qwen2.5-Coder-7B)
- FastAPI Gateway operational
- Redis caching functional
- Docker orchestration working
- Management scripts available

Usage:
bash llm_backend/scripts/start_all.sh  # Interactive model selection
bash llm_backend/scripts/health_check.sh  # Check status

Details: See docs/modules/llm-backend-completion.md
```

**ç¹é«”ä¸­æ–‡ï¼š**
```
ç‹€æ…‹ï¼šå·²æŠ•ç”¢ (2025-11-16)

å·²å®Œæˆï¼š
- vLLM æœå‹™éƒ¨ç½² (Qwen2.5-VL-7B, Qwen2.5-14B, Qwen2.5-Coder-7B)
- FastAPI Gateway é‹ä½œä¸­
- Redis å¿«å–åŠŸèƒ½æ­£å¸¸
- Docker ç·¨æ’é‹ä½œä¸­
- ç®¡ç†è…³æœ¬å¯ç”¨

ä½¿ç”¨ï¼š
bash llm_backend/scripts/start_all.sh  # äº’å‹•å¼æ¨¡å‹é¸æ“‡
bash llm_backend/scripts/health_check.sh  # æª¢æŸ¥ç‹€æ…‹

è©³æƒ…ï¼šè¦‹ docs/modules/llm-backend-completion.md
```

---

### Module 2: Image Generation ğŸ”„ CURRENT (15%)

**English:**
```
Goal: SDXL-based 3D character image generation

Tasks:
1. SDXL + LoRA integration
   - Load SDXL base model
   - Integrate LoRA adapters (character, background, style)
   - Implement dynamic model switching (LLM â†” SDXL)

2. ControlNet guided generation
   - OpenPose for pose control
   - Depth for composition
   - Canny for edge structure

3. Character consistency
   - InstantID / ArcFace embeddings
   - Similarity threshold: 0.60-0.65

Reference: docs/modules/image-generation.md
```

**ç¹é«”ä¸­æ–‡ï¼š**
```
ç›®æ¨™ï¼šåŸºæ–¼ SDXL çš„ 3D è§’è‰²åœ–åƒç”Ÿæˆ

ä»»å‹™ï¼š
1. SDXL + LoRA æ•´åˆ
   - è¼‰å…¥ SDXL åŸºç¤æ¨¡å‹
   - æ•´åˆ LoRA é©é…å™¨ (è§’è‰²ã€èƒŒæ™¯ã€é¢¨æ ¼)
   - å¯¦ä½œå‹•æ…‹æ¨¡å‹åˆ‡æ› (LLM â†” SDXL)

2. ControlNet å¼•å°ç”Ÿæˆ
   - OpenPose å§¿æ…‹æ§åˆ¶
   - Depth æ§‹åœ–å¼•å°
   - Canny é‚Šç·£çµæ§‹

3. è§’è‰²ä¸€è‡´æ€§
   - InstantID / ArcFace embeddings
   - ç›¸ä¼¼åº¦é–€æª»: 0.60-0.65

åƒè€ƒï¼šdocs/modules/image-generation.md
```

---

### Module 3: Voice Synthesis ğŸ“‹ PLANNED (0%)

**English:**
```
Goal: GPT-SoVITS-based character voice synthesis

Tasks:
1. GPT-SoVITS wrapper implementation
2. Voice model training pipeline
3. Voice cloning from film audio
4. Emotion control
5. Multi-language support (EN, IT)

Reference: docs/modules/voice-synthesis.md
```

**ç¹é«”ä¸­æ–‡ï¼š**
```
ç›®æ¨™ï¼šåŸºæ–¼ GPT-SoVITS çš„è§’è‰²èªéŸ³åˆæˆ

ä»»å‹™ï¼š
1. GPT-SoVITS åŒ…è£å™¨å¯¦ä½œ
2. èªéŸ³æ¨¡å‹è¨“ç·´ç®¡é“
3. å¾å½±ç‰‡éŸ³è¨Šå…‹éš†èªéŸ³
4. æƒ…ç·’æ§åˆ¶
5. å¤šèªè¨€æ”¯æ´ (EN, IT)

åƒè€ƒï¼šdocs/modules/voice-synthesis.md
```

---

### Module 4-9: Future Modules ğŸ“‹ PLANNED

**English:**
```
4. Model Manager - Dynamic VRAM management
5. RAG System - Context retrieval
6. Agent Framework - LangGraph + ReAct reasoning
7. Video Analysis - Scene detection, composition
8. Video Editing - AI-powered editing
9. Creative Studio - End-to-end video creation (å¤§å£“è»¸)

Reference: docs/modules/module-progress.md
```

**ç¹é«”ä¸­æ–‡ï¼š**
```
4. Model Manager - å‹•æ…‹ VRAM ç®¡ç†
5. RAG System - ä¸Šä¸‹æ–‡æª¢ç´¢
6. Agent Framework - LangGraph + ReAct æ¨ç†
7. Video Analysis - å ´æ™¯æª¢æ¸¬ã€æ§‹åœ–
8. Video Editing - AI é©…å‹•çš„å‰ªè¼¯
9. Creative Studio - ç«¯åˆ°ç«¯å½±ç‰‡å‰µä½œ (å¤§å£“è»¸)

åƒè€ƒï¼šdocs/modules/module-progress.md
```

---

## ğŸ“‚ File Paths / æª”æ¡ˆè·¯å¾‘

### Shared Resources / å…±ç”¨è³‡æº

**All data paths use `/mnt/data/ai_data/` base:**

```yaml
Film Data / å½±ç‰‡è³‡æ–™:
  /mnt/data/ai_data/datasets/3d-anime/luca/
  /mnt/data/ai_data/datasets/3d-anime/coco/

AI Warehouse / AI å€‰åº«:
  Models: /mnt/c/AI_LLM_projects/ai_warehouse/models/
    â”œâ”€â”€ llm/         # LLM models (Module 1)
    â”œâ”€â”€ diffusion/   # SDXL, ControlNet (Module 2)
    â”œâ”€â”€ tts/         # GPT-SoVITS (Module 3)
    â””â”€â”€ cv/          # Computer vision

  Cache: /mnt/c/AI_LLM_projects/ai_warehouse/cache/
    â”œâ”€â”€ huggingface/
    â”œâ”€â”€ vllm/
    â””â”€â”€ diffusers/

Character Metadata / è§’è‰²å…ƒè³‡æ–™:
  data/films/luca/characters/
  data/films/coco/characters/
```

---

## ğŸ¨ 3D Animation Specific Settings / 3D å‹•ç•«ç‰¹å®šè¨­å®š

### CRITICAL Parameters (DO NOT CHANGE) / é—œéµåƒæ•¸ (ä¸å¯æ›´æ”¹)

```yaml
Segmentation:
  alpha_threshold: 0.15    # Soft anti-aliased edges / æŸ”å’Œé‚Šç·£
  blur_threshold: 80       # Tolerate DoF blur / å…è¨±æ™¯æ·±æ¨¡ç³Š

Clustering:
  min_cluster_size: 10-15  # Smaller than 2D / æ¯” 2D å‹•ç•«å°
  min_samples: 2           # Tighter identity / æ›´ç·Šå¯†çš„èº«ä»½

Training:
  dataset_size: 200-500    # Fewer than 2D / æ¯” 2D å‹•ç•«å°‘
  color_jitter: false      # Breaks PBR / ç ´å£ PBR æè³ª
  horizontal_flip: false   # Breaks asymmetry / ç ´å£éå°ç¨±æ€§

LoRA:
  learning_rate: 1e-4 to 2e-4
  network_rank: 32-64
  epochs: 10-20
```

### Prompt Engineering

```yaml
Positive Keywords:
  - "pixar style"
  - "3d animation"
  - "smooth shading"
  - "pbr materials"
  - "cinematic lighting"
  - "rendered"

Negative Keywords:
  - "2d"
  - "flat"
  - "anime"
  - "sketchy"
  - "low quality"
```

---

## ğŸš€ Quick Commands / å¿«é€ŸæŒ‡ä»¤

### Environment Setup / ç’°å¢ƒè¨­å®š

```bash
# Navigate to project / å°èˆªè‡³å°ˆæ¡ˆ
cd /mnt/c/AI_LLM_projects/animation-ai-studio

# Activate conda environment / å•Ÿå‹• conda ç’°å¢ƒ
conda activate ai_env

# Check GPU / æª¢æŸ¥ GPU
nvidia-smi
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"
```

### LLM Backend Management / LLM å¾Œç«¯ç®¡ç†

```bash
# Start services (interactive) / å•Ÿå‹•æœå‹™ (äº’å‹•å¼)
bash llm_backend/scripts/start_all.sh

# Check health / æª¢æŸ¥å¥åº·ç‹€æ…‹
bash llm_backend/scripts/health_check.sh

# Switch model / åˆ‡æ›æ¨¡å‹
bash llm_backend/scripts/switch_model.sh

# View logs / æŸ¥çœ‹æ—¥èªŒ
bash llm_backend/scripts/logs.sh gateway
bash llm_backend/scripts/logs.sh qwen-vl

# Stop services / åœæ­¢æœå‹™
bash llm_backend/scripts/stop_all.sh
```

---

## ğŸ’¡ Common Questions / å¸¸è¦‹å•é¡Œ

### Q: Why not use Ollama? / ç‚ºä»€éº¼ä¸ç”¨ Ollamaï¼Ÿ

**English:** We need full control and optimization of LLM services. Ollama has limited functionality for our needs.

**ç¹é«”ä¸­æ–‡ï¼š** æˆ‘å€‘éœ€è¦å®Œå…¨æ§åˆ¶å’Œå„ªåŒ– LLM æœå‹™ã€‚Ollama çš„åŠŸèƒ½å°æˆ‘å€‘çš„éœ€æ±‚æœ‰é™ã€‚

---

### Q: Why vLLM? / ç‚ºä»€éº¼ç”¨ vLLMï¼Ÿ

**English:** PagedAttention + Continuous Batching = 24x higher throughput, 2-4x memory efficiency.

**ç¹é«”ä¸­æ–‡ï¼š** PagedAttention + Continuous Batching = ååé‡é«˜ 24 å€ï¼Œè¨˜æ†¶é«”æ•ˆç‡é«˜ 2-4 å€ã€‚

---

### Q: What is LLM's role? / LLM çš„è§’è‰²æ˜¯ä»€éº¼ï¼Ÿ

**English:** LLM is the creative brain - understands intent, plans strategy, selects tools, evaluates quality, iterates autonomously.

**ç¹é«”ä¸­æ–‡ï¼š** LLM æ˜¯å‰µæ„å¤§è…¦ - ç†è§£æ„åœ–ã€è¦åŠƒç­–ç•¥ã€é¸æ“‡å·¥å…·ã€è©•ä¼°å“è³ªã€è‡ªä¸»è¿­ä»£ã€‚

---

### Q: 3D vs 2D animation differences? / 3D å’Œ 2D å‹•ç•«æœ‰ä»€éº¼ä¸åŒï¼Ÿ

**English:** 3D needs soft edges (alpha 0.15), smaller datasets (200-500), no color jitter.

**ç¹é«”ä¸­æ–‡ï¼š** 3D éœ€è¦æŸ”å’Œé‚Šç·£ (alpha 0.15)ã€è¼ƒå°æ•¸æ“šé›† (200-500 å¼µ)ã€ä¸èƒ½ç”¨è‰²å½©æŠ–å‹•ã€‚

---

### Q: Where is data shared? / è³‡æ–™åœ¨å“ªè£¡å…±ç”¨ï¼Ÿ

**English:**
- Film data: `/mnt/data/ai_data/datasets/3d-anime/`
- AI Warehouse: `/mnt/c/AI_LLM_projects/ai_warehouse/`
- Character info: `data/films/`

**ç¹é«”ä¸­æ–‡ï¼š**
- å½±ç‰‡è³‡æ–™: `/mnt/data/ai_data/datasets/3d-anime/`
- AI å€‰åº«: `/mnt/c/AI_LLM_projects/ai_warehouse/`
- è§’è‰²è³‡è¨Š: `data/films/`

---

### Q: Module progress tracking? / å¦‚ä½•è¿½è¹¤æ¨¡çµ„é€²åº¦ï¼Ÿ

**English:** See [docs/modules/module-progress.md](../modules/module-progress.md) for real-time status of all 9 modules.

**ç¹é«”ä¸­æ–‡ï¼š** è¦‹ [docs/modules/module-progress.md](../modules/module-progress.md) æŸ¥çœ‹æ‰€æœ‰ 9 å€‹æ¨¡çµ„çš„å³æ™‚ç‹€æ…‹ã€‚

---

## âœ… Onboarding Checklist / å…¥è·æª¢æŸ¥æ¸…å–®

Before starting work, ensure Claude Code understands:

åœ¨é–‹å§‹å·¥ä½œå‰ï¼Œç¢ºèª Claude Code ç†è§£ï¼š

- [ ] ONLY open-source models / åªç”¨é–‹æºæ¨¡å‹
- [ ] Self-hosted vLLM backend (NOT Ollama) / è‡ªå»º vLLM å¾Œç«¯ (ä¸ç”¨ Ollama)
- [ ] LLM as decision engine (not just tool) / LLM æ˜¯æ±ºç­–å¼•æ“ (ä¸åªæ˜¯å·¥å…·)
- [ ] Optimized for 3D animation / é‡å° 3D å‹•ç•«å„ªåŒ–
- [ ] LangGraph for agents / LangGraph ä½œç‚º Agent æ¡†æ¶
- [ ] Module-based organization / æ¨¡çµ„åŒ–çµ„ç¹”
- [ ] LLM Backend (Module 1) COMPLETE / LLM Backend (æ¨¡çµ„ 1) å®Œæˆ
- [ ] Image Generation (Module 2) IN PROGRESS / Image Generation (æ¨¡çµ„ 2) é€²è¡Œä¸­
- [ ] Shared resources with LoRA pipeline / èˆ‡ LoRA Pipeline å…±äº«è³‡æº
- [ ] Hardware: RTX 5080 16GB (single GPU) / ç¡¬é«”: RTX 5080 16GB (å–®ä¸€ GPU)
- [ ] PyTorch 2.7.0 + CUDA 12.8 IMMUTABLE / PyTorch 2.7.0 + CUDA 12.8 ä¸å¯è®Š
- [ ] Data paths: `/mnt/data/ai_data/...` / è³‡æ–™è·¯å¾‘: `/mnt/data/ai_data/...`

---

## ğŸ“– Additional Resources / å…¶ä»–è³‡æº

### External Documentation / å¤–éƒ¨æ–‡æª”

**English:**
- LangGraph: https://langchain-ai.github.io/langgraph/
- Qwen2.5: https://github.com/QwenLM/Qwen2.5
- GPT-SoVITS: https://github.com/RVC-Boss/GPT-SoVITS
- vLLM: https://docs.vllm.ai/

**ç¹é«”ä¸­æ–‡ï¼š**
- LangGraph: https://langchain-ai.github.io/langgraph/
- Qwen2.5: https://github.com/QwenLM/Qwen2.5
- GPT-SoVITS: https://github.com/RVC-Boss/GPT-SoVITS
- vLLM: https://docs.vllm.ai/

---

**Ready to start? / æº–å‚™å¥½é–‹å§‹äº†å—ï¼Ÿ**

**English:** Ask Claude Code to begin with the current module. Refer to [docs/modules/module-progress.md](../modules/module-progress.md) for current status and [docs/architecture/project-architecture.md](../architecture/project-architecture.md) for overall context.

**ç¹é«”ä¸­æ–‡ï¼š** è®“ Claude Code é–‹å§‹ç•¶å‰æ¨¡çµ„çš„å·¥ä½œã€‚åƒè€ƒ [docs/modules/module-progress.md](../modules/module-progress.md) äº†è§£ç•¶å‰ç‹€æ…‹ï¼Œåƒè€ƒ [docs/architecture/project-architecture.md](../architecture/project-architecture.md) äº†è§£æ•´é«”å…§å®¹ã€‚

---

**Last Updated:** 2025-11-17
**Maintained By:** Animation AI Studio Team
